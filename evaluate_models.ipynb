{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance\n",
    "Evalute model perfomance using the following metrics:\n",
    "- Peak Signal to Noise Ratio (PSNR)\n",
    "- Structural Similarity Index (SSIM)\n",
    "- Spectral Angle Mapper (SAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating image:  spelt_m4.npy\n",
      "Evaluating image:  millet_m4.npy\n",
      "Evaluating image:  mix_s4.npy\n",
      "Evaluating image:  wheatgrass_m4.npy\n",
      "Evaluating image:  rye_l4.npy\n",
      "Evaluating image:  sunflower_l4.npy\n",
      "Evaluating image:  rye_s4.npy\n",
      "Evaluating image:  sunflower_s4.npy\n",
      "Evaluating image:  corn_s4.npy\n",
      "Evaluating image:  flax_m4.npy\n",
      "Evaluating image:  barley_s4.npy\n",
      "Evaluating image:  barley_l4.npy\n",
      "Evaluating image:  mix_l4.npy\n",
      "Evaluating image:  flaxb_l4.npy\n",
      "Evaluating image:  buckwheat_m4.npy\n",
      "Evaluating image:  corn_l4.npy\n",
      "Evaluating image:  pumpkin_m4.npy\n",
      "Evaluating image:  flaxb_s4.npy\n",
      "Mean PSNR SR:  22.2635\n",
      "Mean SSIM SR:  0.7643\n",
      "Mean SAM SR:  0.0371\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchmetrics.image import SpectralAngleMapper\n",
    "\n",
    "def compute_metrics(root_dir, model):\n",
    "    hr_path = root_dir + \"c_hr/\"\n",
    "    sr_path = root_dir + \"models/\" + model + \"/sr/\"\n",
    "\n",
    "    scores = []\n",
    "    img_id_list = os.listdir(hr_path)\n",
    "    for img_id in img_id_list:\n",
    "        print(\"Evaluating image: \", img_id)\n",
    "        \n",
    "        # Load images\n",
    "        img_hr = np.load(os.path.join(hr_path, img_id))\n",
    "        img_sr = np.load(os.path.join(sr_path, img_id))\n",
    "\n",
    "        # Load as tensors\n",
    "        img_hr_tensor = torch.tensor(img_hr, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
    "        img_sr_tensor = torch.tensor(img_sr, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "        psnr_value = psnr(img_hr, img_sr, data_range=img_hr.max() - img_hr.min())\n",
    "        ssim_value = ssim(img_hr, img_sr, data_range=img_hr.max() - img_hr.min(), channel_axis=2)\n",
    "        sam_metric = SpectralAngleMapper() # Read what this does\n",
    "        sam_value = sam_metric(img_hr_tensor, img_sr_tensor).item()\n",
    "        scores.append({'Image_ID': img_id, 'PSNR': psnr_value, 'SSIM': ssim_value, 'SAM': sam_value})\n",
    "\n",
    "    return pd.DataFrame(scores)\n",
    "\n",
    "\n",
    "\n",
    "# Choose model to evaluate\n",
    "model = \"HSI_x2_val6_150000\"\n",
    "data_dir = \"results/\"\n",
    "\n",
    "# Scores for SR and bicubic in a dataframe\n",
    "df_sr = compute_metrics(root_dir=data_dir, model=model)\n",
    "\n",
    "# Save the mean scores to txt\n",
    "with open(f\"{data_dir}/models/{model}/{model}_means.txt\", \"w\") as f:\n",
    "    f.write(\"PSNR: \" + str(round(df_sr['PSNR'].mean(), 4)) + \"\\n\")\n",
    "    f.write(\"SSIM: \" + str(round(df_sr['SSIM'].mean(), 4)) + \"\\n\")\n",
    "    f.write(\"SAM: \" + str(round(df_sr['SAM'].mean(), 4)) + \"\\n\")\n",
    "\n",
    "# Print mean of SR and BI\n",
    "print(\"Mean PSNR SR: \", round(df_sr['PSNR'].mean(), 4))\n",
    "print(\"Mean SSIM SR: \", round(df_sr['SSIM'].mean(), 4))\n",
    "print(\"Mean SAM SR: \", round(df_sr['SAM'].mean(), 4))\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "df_sr.to_csv(f\"{data_dir}/models/{model}/{model}_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating image:  spelt_m4.npy\n",
      "Evaluating image:  millet_m4.npy\n",
      "Evaluating image:  mix_s4.npy\n",
      "Evaluating image:  wheatgrass_m4.npy\n",
      "Evaluating image:  rye_l4.npy\n",
      "Evaluating image:  sunflower_l4.npy\n",
      "Evaluating image:  rye_s4.npy\n",
      "Evaluating image:  sunflower_s4.npy\n",
      "Evaluating image:  corn_s4.npy\n",
      "Evaluating image:  flax_m4.npy\n",
      "Evaluating image:  barley_s4.npy\n",
      "Evaluating image:  barley_l4.npy\n",
      "Evaluating image:  mix_l4.npy\n",
      "Evaluating image:  flaxb_l4.npy\n",
      "Evaluating image:  buckwheat_m4.npy\n",
      "Evaluating image:  corn_l4.npy\n",
      "Evaluating image:  pumpkin_m4.npy\n",
      "Evaluating image:  flaxb_s4.npy\n",
      "Mean PSNR SR:  22.4895\n",
      "Mean SSIM SR:  0.7905\n",
      "Mean SAM SR:  0.0463\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchmetrics.image import SpectralAngleMapper\n",
    "\n",
    "def compute_metrics(root_dir, model):\n",
    "    hr_path = root_dir + \"c_hr/\"\n",
    "    sr_path = root_dir + \"models/\" + model + \"/sr_synth/\"\n",
    "\n",
    "    scores = []\n",
    "    img_id_list = os.listdir(hr_path)\n",
    "    for img_id in img_id_list:\n",
    "        print(\"Evaluating image: \", img_id)\n",
    "        \n",
    "        # Load images\n",
    "        img_hr = np.load(os.path.join(hr_path, img_id))\n",
    "        img_sr = np.load(os.path.join(sr_path, img_id))\n",
    "\n",
    "        # Load as tensors\n",
    "        img_hr_tensor = torch.tensor(img_hr, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
    "        img_sr_tensor = torch.tensor(img_sr, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "        psnr_value = psnr(img_hr, img_sr, data_range=img_hr.max() - img_hr.min())\n",
    "        ssim_value = ssim(img_hr, img_sr, data_range=img_hr.max() - img_hr.min(), channel_axis=2)\n",
    "        sam_metric = SpectralAngleMapper() # Read what this does\n",
    "        sam_value = sam_metric(img_hr_tensor, img_sr_tensor).item()\n",
    "        scores.append({'Image_ID': img_id, 'PSNR': psnr_value, 'SSIM': ssim_value, 'SAM': sam_value})\n",
    "\n",
    "    return pd.DataFrame(scores)\n",
    "\n",
    "\n",
    "\n",
    "# Choose model to evaluate\n",
    "model = \"HSI_x2_val4_150000\"\n",
    "data_dir = \"results/\"\n",
    "\n",
    "# Scores for SR and bicubic in a dataframe\n",
    "df_sr = compute_metrics(root_dir=data_dir, model=model)\n",
    "\n",
    "# Save the mean scores to txt\n",
    "with open(f\"{data_dir}/models/{model}/{model}_synth_means.txt\", \"w\") as f:\n",
    "    f.write(\"PSNR: \" + str(round(df_sr['PSNR'].mean(), 4)) + \"\\n\")\n",
    "    f.write(\"SSIM: \" + str(round(df_sr['SSIM'].mean(), 4)) + \"\\n\")\n",
    "    f.write(\"SAM: \" + str(round(df_sr['SAM'].mean(), 4)) + \"\\n\")\n",
    "\n",
    "# Print mean of SR and BI\n",
    "print(\"Mean PSNR SR: \", round(df_sr['PSNR'].mean(), 4))\n",
    "print(\"Mean SSIM SR: \", round(df_sr['SSIM'].mean(), 4))\n",
    "print(\"Mean SAM SR: \", round(df_sr['SAM'].mean(), 4))\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "df_sr.to_csv(f\"{data_dir}/models/{model}/{model}_synth_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.673, 0.838, 0.056\n"
     ]
    }
   ],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchmetrics.image import SpectralAngleMapper\n",
    "\n",
    "# Select image and model to evaluate\n",
    "img_id = \"barley_s4\"\n",
    "model = \"HSI_x2_val3_150000\"\n",
    "\n",
    "\n",
    "\n",
    "hr_path = \"results/c_hr/\" + img_id + \".npy\"\n",
    "sr_path = \"results/models/\" + model + \"/sr/\" + img_id + \".npy\"\n",
    "# sr_path = \"results/c_sr/\" + img_id + \".npy\"\n",
    "\n",
    "# hr_path = \"data/processed/full_hsi/hr/wheatgrass_s1.npy\"\n",
    "# sr_path = \"Real-ESRGAN/experiments/finetune_HSIx2_val/visualization/wheatgrass_s1/wheatgrass_s1_32800.npy\"\n",
    "\n",
    "\n",
    "def compute_metrics(hr_path, sr_path):\n",
    "    # Load images\n",
    "    img_hr = np.load(hr_path)\n",
    "    img_sr = np.load(sr_path)\n",
    "\n",
    "    # Load as tensors\n",
    "    img_hr_tensor = torch.tensor(img_hr, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
    "    img_sr_tensor = torch.tensor(img_sr, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "\n",
    "    psnr_value = round(psnr(img_hr, img_sr, data_range=img_hr.max() - img_hr.min()), 3)\n",
    "    ssim_value = round(ssim(img_hr, img_sr, data_range=img_hr.max() - img_hr.min(), channel_axis=2), 3)\n",
    "    sam_metric = SpectralAngleMapper()\n",
    "    sam_value = round(sam_metric(img_hr_tensor, img_sr_tensor).item(), 3)\n",
    "\n",
    "    print(f\"{psnr_value}, {ssim_value}, {sam_value}\")\n",
    "\n",
    "\n",
    "compute_metrics(hr_path, sr_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate RGB from HSI for visual evaluation\n",
    "Use channels [0, 12, 23] to simulate RGB image from HSI image. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def npy_to_rgb(input_folder, target_folder, mode):\n",
    "\n",
    "    if mode == \"sr\":\n",
    "        inputs = os.listdir(input_folder)\n",
    "    elif mode == \"hr\":\n",
    "        input_folder = \"results/c_hr/\"\n",
    "        inputs = os.listdir(input_folder)\n",
    "    elif mode == \"x_bi\":\n",
    "        input_folder = \"results/c_bi_480/\"\n",
    "        inputs = os.listdir(input_folder)\n",
    "\n",
    "    for file_name in inputs:\n",
    "\n",
    "        # Load npy file\n",
    "        image = np.load(input_folder + file_name)\n",
    "        \n",
    "        # Select only 3 channels\n",
    "        rgb_array = image[:, :, [0, 12, 23]] * 255\n",
    "\n",
    "        # Save the image as a jpg file\n",
    "        cv.imwrite(target_folder + file_name.split('/')[-1][:-4] + \"_\" + mode + \".jpg\", rgb_array)\n",
    "\n",
    "\n",
    "mode = \"x_bi\"\n",
    "model = \"HSI_x2_v3_50000\"\n",
    "input_folder = \"results/models/\" + model + \"/\" + mode + \"/\"\n",
    "target_folder = \"results/simulated_rgb/\" + model + \"/\"\n",
    "rgb_array = npy_to_rgb(input_folder, target_folder, mode=mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
